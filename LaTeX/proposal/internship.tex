\documentclass{article}

\usepackage[utf8]{inputenc}
\usepackage{amsmath,amssymb,amsthm}

\title{Internship proposal: Minimizing universes for a formal library of proofs}
\author{François Thiré}
\date{\today}

\newcommand{\universo}{\texttt{Universo}}

\begin{document}
\maketitle
\section{At the beginning of Type Theory}
In the beginning of the twentieth century, Russel found a paradox in the naive axiomatization of set theory that was proposed twenty years earlier by Cantor. Two solutions were found to this paradox:
\begin{itemize}
\item The first one was to strengthen the axioms so that some \textit{exotics} sets could not be construct, this led to the widely known axiomatization called ZFC
\item The second one was to give a \textit{type} to the objects of the logic as it was done in the \textit{Principia of Mathematica}, which led to type theory.
\end{itemize}

While mathematicians uses mostly ZFC nowadays, formal systems used to automatically check the validity of proofs preferred to follow the second solution. Most of them are based upon various extensions of type theory as it was proposed in the \textit{Principia of Mathematica}. In type theory, each object of the logic has a type: For example, \(0\) has type \(\mathbb{N}\), the function \(x \mapsto x^2\) has type \(\mathbb{N} \to \mathbb{N}\). But \(\mathbb{N}\) is also an object of the logic and hence should have a type. Usually, this type is denoted \texttt{Type} and is called a \textit{universe} because it is inhabited by other types. Once again, \texttt{Type} being an object of the logic, it should have also a type. One may think that one universe should be enough to the logic and hence, we could have \texttt{Type} of type \texttt{Type}. However, Russel noticed that this naive idea gives rise again to paradox. One more time, the solutions of this paradox give rise to two different solutions:

\begin{itemize}
\item Either, we stratify the system by having an infinite hierarchy of universes by having \texttt{Type}\(_0\), \texttt{Type}\(_1\), ... and then, the type of \(\mathbb{N}\) is \texttt{Type}\(_0\), the type of \texttt{Type}\(_0\) is \texttt{Type}\(_1\)...
\item Either, we let \texttt{Type} of type \texttt{Kind}, the latter however does not have a type
\end{itemize}

Today, both solutions have been used in different systems. The first one is used for example by Coq, Agda, or Lean while the second solution is used by the HOL family provers.

\section{Interoperability}

The area of formal prover is one the rare area of computer science which is not guided by standards. Hence, each system, has developed its own standard and its own library of proofs. As a result, theorems such as Fermat's little theorem and all the \(300\) arithmetic lemmas needed to prove it are proved many times for each system. Formalizing mathematical results is hard and requires several man-months to get a full formalization of a proof in one system. To overcome this issue, it would be interesting to have an automatic translation that translates a proof formalized in a system \(A\) to a system \(B\).

A first step toward this goal is the use of logical frameworks which are systems that can express several logics. These systems gives a common framework to write proof transformations. Recently, progress has been made with the logical framework Dedukti by sharing a proof of Fermat's little theorem between \(6\) different formal systems such as Coq, Lean, PVS or OpenTheory.

However, in general, it is not possible to share any proof since these systems are based upon different logics. For example, in a classical system the excluded middle is provable while it is not in an intuitionistic one. Besides, one may avoid encodings (such as the double negation of Godël) so that theorems are still usable at the end. Hence, while it was possible to share arithmetic proofs, it might not be the case with more complex proofs that use classical logic or advanced features of the system. Such developments include the formalization of mathematical analysis or category theory.

\section{Interoperability and universes}

In the setting of Dedukti, interoperability is performed in a similar way than a compiler for programming language: Proofs are programs (in the style of Curry-Howard isomorphism) and several transformations are performed to get at the end proofs expressed in the target system. Among all the transformations, one is specific to universes: If one is interested to go from a system with an infinite hierarchy of universes such as Coq and want to go to a system using only a finite number of universes such as OpenTheory, one needs to \textit{minimize} the number of universes needed in these proofs. Minimizing universes is not a feature offered by the systems implementing this infinite hierarchy of universes because it is not needed to check the validity of a proof. \universo{}, is a tool written for Dedukti proofs that performs this minimization process. \universo{} was used for example to minimize universes in the proof of Fermat's little theorem to go from a proof using \(5\) universes to a proof using only \(3\) universes. However, the library of the formal system Matita has more complex proofs that requires at least \(4\) universes and hence, cannot be translated directly into OpenTheory.

\section{Objectives}

The objectives of this internship are the following:
\paragraph{Extending \universo{}:}
On the practical point of view, \universo{} has currently some limitations:
\begin{itemize}
\item It gives a minimal number of universes needed, but it does not give any explanation
\item It cannot isolate a part of the library that would be valid using only \(3\) universes for example
\end{itemize}

One objective of the internship is therefore to adapt \universo{} to overcome these two limitations.

\paragraph{Reverse mathematics}

The validity criterion for \universo{} is only syntactic: If \universo{} says that the proof of a theorem needs at least \(n\) universes, this result only applies for this particular proof. It does not mean that any proof of that theorem needs \(n\) universes. For example, a computation step such as a \(\beta\)-reduction can reduce the number of universes needed. In the case of the Matita's library, it might be interesting to understand if really \(4\) universes are needed to prove these theorems, or instead, it would be possible to reformulate the proofs so that less universes could be used.

\end{document}