\documentclass[conference]{IEEEtran}

\usepackage[utf8]{inputenc}

\usepackage{amsmath}
\usepackage{amssymb}


\usepackage[standard]{ntheorem}

\usepackage{mathpartir}

\usepackage{mdframed}
\iflocal
\usepackage[finalizecache]{minted}
\renewcommand{\MintedPygmentize}{/home/fthire/Mercurial/pygmentize-fork/pygmentize}
\else
\usepackage[frozencache]{minted}
\fi

\newcommand{\lfmt}{\ensuremath{\lambda\Pi\text{-modulo theory}}}

\newcommand{\defn}{\ensuremath{:=}}

\newcommand{\tabs}[3]{\ensuremath{\lambda{#1}\,{:}\,{#2}.\,{#3}}}

\newcommand{\tapp}[2]{\ensuremath{{#1}~{#2}}}

\newcommand{\tpi}[3]{\ensuremath{\Pi{#1}\,{:}\,{#2}.\,{#3}}}

\newcommand{\ttype}{\ensuremath{\mathbf{Type}}}

\newcommand{\tkind}{\ensuremath{\mathbf{Kind}}}

\newcommand{\universo}{\textsc{Universo}}

\newcommand{\dkmeta}{\textsc{Dkmeta}}

\newcommand{\erasure}[1]{\ensuremath{|#1|}}
\newcommand{\absT}[3]{\lambda~#1^{#2}.#3}
\newcommand{\PiT}[3]{\Pi~#1^{#2}.#3}
\begin{document}
\title{Minimization of Universes for Interoperability in Dedukti}
\author{\IEEEauthorblockN{François Thiré}
\IEEEauthorblockA{LSV, ENS Paris-Saclay, CNRS, Université Paris-Saclay, INRIA\\
Email: francois.thire@lsv.fr}}
\maketitle

\begin{abstract}
The abstract goes here.
\end{abstract}

% \section{The algorithm}
% \label{sec:algo}
% Minimization of universes can be presented in an abstract way on a simpler theory than the one implemented in Coq. We are going to use a variant of the Calculus of Constructions with Universes as presented in~\ref{fig:sttsyntax}. Then, in TODO, we will present how we can extend this algorithm for a theory implemented in a system such as Coq or Matita.

% \begin{figure}
%   \centering
%   \begin{tabular}{lccl}
%     \textbf{Variables} & \(x,y,z,\dots\) & & \\
%     \textbf{Terms} & \(A,B,t,u\) & \(\defn\) & \(x~|~\tpi{x}{A}{B} ~|~\tabs{x}{A}{u} ~|~ \tapp{t}{u} \)\\

%   \end{tabular}
%   \caption{\lfmt{}}
%   \label{fig:sttsyntax}
% \end{figure}

% \section{Being independent from the theory}

% Universes are implemented in several systems: Coq, Agda, Lean, Matita... However, each system implements a variant of this hierarchy: Agda does not have an impredicative universe, Coq has a predicative universe Set, etc... However, the algorithm presented above can be easely adapted for all these variants. While implemented \universo{}, we had the goal that it should be easy to use \universo{} in one variant or an other without having to fork the whole software. The idea is that \universo{} has its own hierarchy of universes, and all the hierarchies of the systems enumerated above can be embedded in the one of \universo. This embedding can be given by the user as rewrite rules directly expressed in the Dedukti syntax. This technique may be used for other goals than \universo{}. In the case of \universo{}. this embedding requires the user to write three files:
% \begin{itemize}
% \item An input file to translate universes from its own theory to the one of \universo{}. This is used while elaborating the terms.
% \item A theory file used to translate universes of the theory file to the one of \universo{}.
% \item An output file to translate back universes{} from \universo{} to the one of the original theory.
% \end{itemize}

% If you want to use \universo{} with your theory, you just need to give these three files to make \universo{} works.

\section{CTS}

Using typical ambiguity such as in TODO, one may generate constraints while type checking terms. Consistency of these constraints implies that the terms are well-typed. However, one have to invent a procedure to solve these constraints. For all the systems presented above, this is done by an ad-hoc algorithm implemented by those systems. This is doable because each of these system implement one particular CTS. However, it is not clear how these algorithms could be extended for all \textit{convergent} CTS. We aim to solve this issue by calling a SMT solver instead. However, one has to provide a model for the SMT solver.n  If the maximum number of universes needed is known, then this model can given in a logic with non-interpreted symbols. However, if it is unknown, then a number of unbounded universes is needed, even if in practice most of the proofs use at most four or five universes. Hence, this require to use a more sophisticated logic. TODO: using injectivity on constructor is sufficient?

% 0 : nat
% S : nat -> nat
% Prop : Sort
% Type : nat -> Sort
% succ (Prop) --> Type 0
% succ (Type x) --> Type (S x)

% forall x, ~ Prop = Type x
% succ Prop = Type 0
% succ (Type x) = Type (S x)
%
% forall x, 0 <> S x
% forall x, S x = S y ==> x = y
% forall x, Type x = Type y ==> x = y

\section{CTS in Dedukti}

We revisit here the known encoding of PTS and Cumulative Type Systems in Dedukti. Introducing \textit{typical ambiguity} in Dedukti with \universo{} led us to change a little the encodings of CTS (and PTS) in Dedukti. The encoding given by A. Assaf gives the following type for the explicit \texttt{lift} operator:
\begin{minted}{dedukti}
  lift : s1 : Sort -> s2 : Sort -> Univ s1 -> Univ (max s1 s2).
\end{minted}

Why the return type lives in \mintinline{dedukti}{max s1 s2}? This is to ensure consistency of our encoding, otherwise it would be possible to go from a higher universe to a lower one. However, this little hack makes the encoding a little bit complicated. Indeed, in this encoding, some \textit{canonicity rules} that allows to compute a canonical form when \textit{lift} and \textit{prod} appear together needs other rules to be type checked. Moreover, by doing so, the encoding is clearly not confluent which is needed to prove subject reduction. To overcome this issue, Assaf claims the consistency of its encoding only when the type of universes is \textit{confined}\footnote{TODO}. It would be easier if the return type of \textit{lift} would be : \mintinline{dedukti}{univ s2}, but then, how to ensure that \texttt{s1} is \textit{smaller} then \texttt{s2}? Our idea is to give the following type to the lift symbol:
\begin{minted}{dedukti}
  lift : s1 : Sort -> s2 : Sort -> Cumul s1 s2 -> Univ s1 -> Univ (max s1 s2).
\end{minted}
where \mintinline{dedukti}{Cumul} is a definable symbol that reduces to \texttt{True} only if \texttt{s1} is smaller than \texttt{s2}.
\section{Universo}

\universo{} is a tool written in OCaml that was designed to minimize the number of universes needed in a proof written in the Calculus Of Inductive Constructions. However, the current implementation works only if proofs are expressed first in Dedukti. The idea behind \universo{} is quite simple and works in \(4\) steps:
\begin{enumerate}
\item Elaborate the terms by replacing each occurence of a universe by a variable
\item Use Dedukti to type checks the elaborated terms and generate constraints over these variables
\item Solve the constraints (using a SMT solver for example)
\item Reconstruct the terms with the solution given at the previous step
\end{enumerate}

In practice, the number of variables or constraints can be fairly large: about hundreds of thousands of variables and thousands of constraints. This is because we use an encoding of the Calculus of Inductive Constructions in Dedukti. However, we noticed that with some well-suited optimizations, an SMT solver could solve the problem quickly (in a few seconds).

The correction of our method relies on the second step: We \textit{hack} the convertibility test of Dedukti to generate constraints over universes. Let us see how it works. Suppose we have the following term:

\begin{minted}[breaklines]{coq}
  Parameter eq : forall (A:Type[2]), A -> A -> Prop.

  Axiom refl forall (A:Type[2]), forall (x:A), eq A x x.
\end{minted}

It will be enconded this way in Dedukti\footnote{For esthetic reasons, this is not really Dedukti code} :

\begin{minted}[breaklines]{dedukti}
eq :
  cic.Term Univ.3
    (cic.prod Univ.3 Univ.2
       (cic.univ Univ.2)
       (A : cic.Univ Univ.2 =>
        cic.prod Univ.2
          (cic.type Univ.2 A
          (_x : cic.Term Univ.2 A =>
           cic.prod Univ.2 Univ.0 A
             (__ : cic.Term Univ.2 A =>
              cic.univ Univ.Prop)))).

refl :
  cic.Term Univ.Prop
    (cic.prod Univ.3 Univ.Prop
       (cic.univ Univ.2)
       (A : cic.Univ Univ.2 =>
        cic.prod Univ.2 cic.prop A
          (x : cic.Term Univ.2 A =>
           matita_basics_logic.eq
             (cic.lift Univ.2 Univ.2 A) x x))).
\end{minted}

After the first elaboration step, we get these terms (that are ill-typed):
\begin{minted}[breaklines]{dedukti}
eq :
  cic.Term ?0
    (cic.prod ?1 ?2 (cic.univ ?3)
       (A : cic.Univ ?10 =>
        cic.prod ?4 ?5 A
          (_x : cic.Term ?9 A =>
           cic.prod ?6 ?7 A
             (__ : cic.Term ?8 A =>
              cic.univ cic.prop)))).

refl :
  cic.Term cic.prop
    (cic.prod ?11 cic.prop
       (cic.univ ?12)
       (A : cic.Univ ?17 =>
        cic.prod ?13 cic.prop A
          (x : cic.Term ?16 A =>
           matita_basics_logic.eq (cic.lift ?14 ?15 A) x x))).
\end{minted}

Notice that \mintinline{dedukti}{cic.prop} is not replaced by a variable because we know that it will stay \mintinline{dedukti}{cic.prop} through the normalization process. Notice also that the encoding creates \(18\) variables while there is only one in the original term. This is not a big issue and we will see later how we can resolve this problem.

Then, we ask Dedukti to type check these terms. Since the terms are ill-typed, Dedukti will eventually fail. For example, while type checking the terms, Dedukti tries to check whether \mintinline{dedukti}{cic.succ ?3} and \mintinline{dedukti}{?1} are convertible. In that case, \universo{} takes over, generates the constraint: \(?1 \stackrel{?}{=} ?3 + 1\) and returns \texttt{true}. Once the terms are type-checked, \universo{} has generated the following constraints:
\begin{align*}
  ?1 &= ?3 + 1 \\
  ?9 &= ?4     & ?10 &= ?3\\
  ?8 &= ?6     & ?10 &= ?4\\
  ?7 &= \mathtt{Type0} & ?10 &= ?9\\
  ?5 &= \mathbf{rule}(?6,?7)     & ?10 &= ?6\\
  ?2 &= \mathbf{rule}(?4,?5)     & ?10 &= ?8\\
  ?0 &= \mathbf{rule}(?1,?2)\\
  \\
  ?11 &= ?12 + 1 & ?17 &= ?12\\
  ?16 &= ?13 & ?17 &= ?13\\
  ?16 &= ?14 & ?17 &= ?16\\
  ?3 &= \mathbf{max}(?14,?15) & ?17 &= ?14\\
\end{align*}

We can see easily that the minimal solution is given by
\begin{align*}
  \{?0,?1,?2,?5,?7,?11\} \to \mathtt{Type0}\\
  \{?3,?4,?6,?8,?9,?10,?12, ?13, ?14, ?15, ?16, ?17\} \to \mathtt{Prop}
\end{align*}
Then, replacing the solution to our original term give us:

\begin{minted}[breaklines]{dedukti}
eq :
  cic.Term (cic.type cic.z)
    (cic.prod (cic.type cic.z) (cic.type cic.z) (cic.univ cic.prop)
       (A : cic.Univ cic.prop =>
        cic.prod cic.prop (cic.type cic.z) A
          (_x : cic.Term cic.prop A =>
           cic.prod cic.prop (cic.type cic.z) A
             (__ : cic.Term cic.prop A =>
              cic.univ cic.prop)))).

refl :
  cic.Term cic.prop
    (cic.prod (cic.type cic.z) cic.prop
       (cic.univ cic.prop)
       (A : cic.Univ cic.prop =>
        cic.prod cic.prop cic.prop A
          (x : cic.Term cic.prop A =>
           matita_basics_logic.eq
             (cic.lift cic.prop cic.prop A) x x))).
\end{minted}

We have decided to delegate the solving of the constraint system to an SMT instead of having an ad-hoc algorithm for several reasons:
\begin{itemize}
\item SMT are good to handle thousands of variables and constraints in an efficient way
\item In our examples SMT are fast enough
\item We can use the incremental feature of SMT solvers to solve partially a system
\item We can parameterized the SMT so that we can tweak easily our problem. For example, to go from an impredicative theory to a predicative one
\end{itemize}

\section{Correction}


% Given a typing judgement \(\Gamma \vdash t : A\), \universo{} computes three things:
% \begin{itemize}
% \item A triple \(\Gamma', t', A'\)
% \item A set of constraints \(\mathcal{C}\)
% \item A substitution \(\sigma_U\)
% \end{itemize}

% where \(\Gamma',t',A'\) is defined as:
% \begin{itemize}
% \item \(\Gamma' = \sigma_U(|\Gamma|)\)
% \item \(t' = \sigma_U(|t|)\)
% \item \(A' = \sigma_U(|A|)\)
% \end{itemize}
% \begin{definition}
%   We define the erasure function \(\erasure{\cdot}\) inductively as follow
% \begin{align*}
%   \erasure{s} & = \mathtt{fresh}~uvar\\
%   \\
%   \erasure{x} & = x \\
%   \erasure{M N} &= \erasure{M}~\erasure{N}\\
%   \erasure{\absT{x}{A}{M}} &= \absT{x}{\erasure{A}}{\erasure{M}}\\
%   \erasure{\PiT{x}{A}{M}} &= \PiT{x}{\erasure{A}}{\erasure{M}}\\
%   \\
%   \erasure{\emptyset} &= \emptyset\\
%   \erasure{\Gamma,x : A} &= \erasure{\Gamma}, x : \erasure{A}
% \end{align*}
% \end{definition}
% \begin{lemma}
% If \(\Gamma \vdash t : A\) and \(\sigma \models \mathcal{C}\) then \[\sigma(|\Gamma|) \vdash \sigma(|t|) : \sigma(|A|)\]
% \end{lemma}

% \begin{remark}
%   There is always a \(\sigma\) such that \(\sigma(|\Gamma|) \vdash \sigma(|t|) : \sigma(|A|)\). This \(\sigma\) is the \textit{inverse} of the erasure function. Moreover, it has the property that \(\sigma \models \mathcal{C}\).
% \end{remark}

% \begin{Lemma}
% \(\sigma_U \models \mathcal{C}\)
% \end{Lemma}
%  \begin{proof}
%    By definition of \(\sigma_U\)
%  \end{proof}

% \begin{definition}
%   We define \(\sigma \preceq \sigma'\) as \[\max_{x\in Dom(\sigma)}(\sigma(x)) \leq \max_{x\in Dom(\sigma)}(\sigma(x))\]
% \end{definition}

% \begin{lemma}
%   Forall \(\sigma\), if \(\sigma(|\Gamma|) \vdash \sigma(|t|) : \sigma(|A|)\) then \[\sigma_U \preceq \sigma\]
% \end{lemma}

% \begin{lemma}
%   Forall \(n\), \(\mathcal{C}^{cic}\) and \(\mathcal{C}^{n}\) are \(n\)-equisatisfiable.
% \end{lemma}

% Proving the correction of \universo{} is a little bit tricky for two reasons:
% \begin{itemize}
% \item What is the statement that we want to prove?
% \item How we can relate constraints and typing judgement through an encoding in Dedukti?
% \end{itemize}

% First of all, we want to say that \universo{} preserves the typing:
% \[ \Gamma \vdash a : T \Rightarrow \Gamma' \vdash a' : T'\]
% But how \(T\) and \(T'\) are related for example? And what is the specification of \(T'\)?

% We solve this issues in two steps:
% \begin{itemize}
% \item We define an erasure function \(| \phantom{A}|\) that replaces each occurence of a universe by a variable, the same way it is done in \universo{} during the first step
% \item Then we define a judgment \(\Gamma \vdash_{\sigma} t : T\) defined for the terms erased where \(\sigma\) is a substitution that mapped universe variables to concrete universes
% \item To prove the minimality, we define an order these substitutions
% \end{itemize}

\section{To a predicative theory}

While doing interoperability, we might be interesting to translate proofs from an impredicative system to a predicative one when it is possible. To achieve that purpose, one may use \universo. Indeed, to do that, we just need to make three subtle changes in \universo:
\begin{itemize}
\item During the elaboration step, also elaborate the universo \texttt{Prop}
\item Tell to the solver that no variable can be assigned to \texttt{Prop}
\item Remove the upper bound on the variables
\end{itemize}

\section{An encoding of floatting universes}

Finally, notice that \universo{} gives us a way to represent floatting universes in Dedukti. Indeed, each variable can be declared as a constant and each constraint as a rewrite rule.

Then the consistency of the theory encoded this way can be given in two different ways:

\begin{itemize}
\item Run a \universo{} on the rules
\item Check that the rewrite system generated this way is convergent
\end{itemize}

However, this representation is not practical. This encoding would add thousands rules on the same symbol, something that Dedukti cannot handle right now due to technical details.

\section{Optimization}

\section{Implementation}

\subsection{Dedukti}
For each file \mintinline{bash}{A.dk}, our tool generate four files:
\begin{itemize}
\item \mintinline{bash}{A_elab.dk}
\item \mintinline{bash}{A_univ_decl.dk}
\item \mintinline{bash}{A_univ_constraints.dk}
\item \mintinline{bash}{A_univ_solution.dk}
\end{itemize}

The first one is the file with all universes replaced by a variable. The second one, contains declarations for each universe variables. The third one contains constraints encoded as rewrite rules.
Finally, the last one contains the solution given by the SMT solver.

The first file can be type checked in two ways:
\begin{itemize}
\item By importing the declaration and the constraints (this corresponds to an encoding of floatting universes)
\item By importing the declaration and the solution directly
\end{itemize}

Several options can be passed to \universo{} to parameterized the tool:
\begin{itemize}
\item \mintinline{bash}{--no-minimization} : do no try to minimize (use for the solver)
\item \mintinline{bash}{--elaboration} : only generate the elaborated file
\item \mintinline{bash}{--check} : generate the constraints file from the elaborated file
\item \mintinline{bash}{--solve} : generate the solution file from the constraints files and all its dependencies
\item \mintinline{bash}{--predicative} : prop is elaborated and is not part of the model. Implies \mintinline{bash}{--no-minimization}.
\end{itemize}



\end{document}